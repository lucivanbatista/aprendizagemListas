{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model, metrics, datasets\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mylibs import transform as tf\n",
    "from mylibs import resample as rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Crie os seguintes arquivos com extensão .py e implemente os métodos definidos para cada um deles:\n",
    "* transform.py\n",
    "    - standardize\n",
    "    - normalize\n",
    "* resample.py\n",
    "    - split_k_fold(n_elem, n_splits=3, shuffle=True, seed=0)\n",
    "    - n_elem - número total de elementos.\n",
    "    - n_split - número de folds. Mínimo: 2.\n",
    "    - shuffle - aleatoriza a ordem dos dados (True) ou não (False).\n",
    "    - seed - determina uma semente para geração de números aleatórios ou não (None).\n",
    "    - Retorno: 2 arrays (idx_train e idx_test), cada um com n_splits elementos: \n",
    "    - um com os índices de treino. Exemplo para n_splits=3, teremos idx_train[0], idx_train[1] e idx_train[2].\n",
    "    - um com os índices de teste. Exemplo para n_splits=3, teremos idx_test[0], idx_test[1] e idx_test[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.random.rand(20) # 20 valores\n",
    "x = (x * 100).round(2) # valores até 100\n",
    "x = np.resize(x, (20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56025437],\n",
       "       [0.73661897],\n",
       "       [0.61748808],\n",
       "       [0.55612083],\n",
       "       [0.42766296],\n",
       "       [0.66316905],\n",
       "       [0.44239534],\n",
       "       [0.92379438],\n",
       "       [1.        ],\n",
       "       [0.38494966],\n",
       "       [0.81770005],\n",
       "       [0.53916269],\n",
       "       [0.58060413],\n",
       "       [0.95961844],\n",
       "       [0.05384208],\n",
       "       [0.0709062 ],\n",
       "       [0.        ],\n",
       "       [0.86104928],\n",
       "       [0.80339163],\n",
       "       [0.90068892]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11870903],\n",
       "       [ 0.48434953],\n",
       "       [ 0.07699507],\n",
       "       [-0.13284322],\n",
       "       [-0.5720902 ],\n",
       "       [ 0.23319593],\n",
       "       [-0.52171451],\n",
       "       [ 1.12437442],\n",
       "       [ 1.38495081],\n",
       "       [-0.71814345],\n",
       "       [ 0.761597  ],\n",
       "       [-0.19082962],\n",
       "       [-0.04912535],\n",
       "       [ 1.24687069],\n",
       "       [-1.85032791],\n",
       "       [-1.79197909],\n",
       "       [-2.03443473],\n",
       "       [ 0.90982474],\n",
       "       [ 0.71267098],\n",
       "       [ 1.04536795]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.standardize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, train = rs.slipt_k_fold(20, 5, True, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2,  8,  6, 19, 15,  4, 16, 12,  9,  1,  0,  7, 14, 17,  3, 18]),\n",
       " array([13, 11, 10,  5, 15,  4, 16, 12,  9,  1,  0,  7, 14, 17,  3, 18]),\n",
       " array([13, 11, 10,  5,  2,  8,  6, 19,  9,  1,  0,  7, 14, 17,  3, 18]),\n",
       " array([13, 11, 10,  5,  2,  8,  6, 19, 15,  4, 16, 12, 14, 17,  3, 18]),\n",
       " array([13, 11, 10,  5,  2,  8,  6, 19, 15,  4, 16, 12,  9,  1,  0,  7])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([13, 11, 10,  5]),\n",
       " array([ 2,  8,  6, 19]),\n",
       " array([15,  4, 16, 12]),\n",
       " array([9, 1, 0, 7]),\n",
       " array([14, 17,  3, 18])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.093</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>10.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.132</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99734</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.77</td>\n",
       "      <td>11.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.99458</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>10.3</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.214</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.073</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "407            12.0              0.39         0.66             3.0      0.093   \n",
       "1220           10.9              0.32         0.52             1.8      0.132   \n",
       "1200            7.7              0.57         0.21             1.5      0.069   \n",
       "308            10.3              0.43         0.44             2.4      0.214   \n",
       "1328            6.5              0.52         0.11             1.8      0.073   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "407                  12.0                  30.0  0.99960  3.18       0.63   \n",
       "1220                 17.0                  44.0  0.99734  3.28       0.77   \n",
       "1200                  4.0                   9.0  0.99458  3.16       0.54   \n",
       "308                   5.0                  12.0  0.99940  3.19       0.63   \n",
       "1328                 13.0                  38.0  0.99550  3.34       0.52   \n",
       "\n",
       "      alcohol  quality  \n",
       "407      10.8        7  \n",
       "1220     11.5        6  \n",
       "1200      9.8        6  \n",
       "308       9.5        6  \n",
       "1328      9.3        5  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "idx_test, idx_train = rs.slipt_k_fold(data.shape[0], k, True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1366,  551, 1068,  167,  176,  120, 1404,  392, 1476, 1414, 1346,\n",
       "        1241,  694, 1477, 1402,  132, 1537, 1263,  768, 1237,  399,  543,\n",
       "        1434, 1064,   29, 1090, 1487,  466,  857,  269,  701,  901,  603,\n",
       "         362, 1115,  753, 1419,  126, 1542,  783,  649,  642,   33,   47,\n",
       "        1517,  823, 1447,  217,  414,  103,  141, 1563, 1463,  855,   82,\n",
       "        1445,  191, 1282,  247, 1103, 1097,  737,  115, 1458, 1189,   51,\n",
       "        1545,  166, 1128,  902, 1082,  475,  391,  598,   86, 1104,  928,\n",
       "        1049, 1319,  591,  266,  746, 1576, 1125, 1022,  844,  995,  299,\n",
       "         368,  756,  618,  246, 1448,  866, 1421, 1484, 1014,  149,  748,\n",
       "        1287,  795,  395, 1172,  893, 1316, 1057,  345, 1170,  492,  825,\n",
       "         837,  833,  798,  231, 1524,  328, 1353, 1488, 1296,  552, 1390,\n",
       "         410, 1358,  903,  659,  480, 1262,  610,  438,  476, 1105, 1009,\n",
       "         671,  139,  215, 1260,  495,  949,  773, 1047, 1450,  117,  156,\n",
       "          15,  602,  264,   12,  870,  377,  370, 1436,  544, 1075, 1480,\n",
       "        1258,  620,  292, 1073,  987,  944,  790,  615,  186,  707, 1076,\n",
       "         660,  452,  867, 1584,    0,  633,  178,  853,  527, 1367, 1222,\n",
       "        1504,  626,  175,  444, 1239, 1163,  194, 1036,  974,  181,  852,\n",
       "         806,  574,  146,  504,  342,  733,  937, 1329,  431,  164,  347,\n",
       "         133, 1496,  136, 1080,  807, 1510,  202, 1243,  316, 1008,  991,\n",
       "         687,  521, 1020, 1295, 1568, 1107, 1416,  662,  767, 1124,  777,\n",
       "        1130, 1481,  208,  533,  436,  503,  910, 1303,  385,  424,  892,\n",
       "         846, 1522,  861,  483, 1431, 1149,  607,  981, 1152,   71,   26,\n",
       "        1592,  793, 1478, 1540, 1491,  488,  729,  461,  816,  517,  222,\n",
       "         970,  230, 1360, 1321,  704,  283,  851,  845,  356,   73, 1363,\n",
       "        1493, 1473, 1422, 1371, 1508,  888,    4,  732, 1161, 1173, 1278,\n",
       "         433, 1308,  236,  755, 1116,   44,  975, 1198, 1465,    7, 1171,\n",
       "        1164, 1454,  293, 1240, 1289,  108,  421,  346,  216, 1217,  782,\n",
       "         118,  779, 1472, 1157,  708, 1530,  962,   70, 1357,   46,  253,\n",
       "         787, 1235,  300,  212, 1109,  509, 1389, 1013,   87,  952, 1438,\n",
       "        1494]),\n",
       " array([ 720,  425,  917,  288,  499, 1147,  894,  669,  209,   50, 1123,\n",
       "         747,  695, 1268, 1497,  734,  522,  840, 1349,  307, 1029,  958,\n",
       "         587,  703, 1322,  463,  938,  797,  860, 1160,  110,  566,  482,\n",
       "        1155,  430,  185,  739,  161,  609,  539,  314,  927,  470, 1021,\n",
       "         619, 1417,  348,  353,  675,  629, 1065,  144,  534,  957,  977,\n",
       "        1204,  685,  151, 1506,  548,  417, 1499, 1385,  664, 1575,  953,\n",
       "         606, 1293,  997,  856,  233,  661,  419,  906, 1534, 1405,  416,\n",
       "         581,  464,    5,  322,  513,  785,  487,  229, 1141, 1376,  501,\n",
       "        1373,  404,  616, 1056,  812,  600, 1325,  432,  290,  891,   76,\n",
       "        1475,  838, 1046,  859,  831,  335, 1011,  180,  979,  862,  538,\n",
       "         393,  315,  123,  789, 1158, 1257, 1121,  211,  286, 1315,  994,\n",
       "        1413,  723, 1304,  668, 1052, 1223,  427,   78,  573, 1398,  586,\n",
       "        1365,  611,  791,  731,  232,  441, 1206,  189, 1554, 1393,  301,\n",
       "         653, 1202,  989, 1285, 1579,  334,  728,  124, 1410, 1392,  275,\n",
       "        1552, 1039,   72, 1219, 1340,  184,  171,   35,  265,  772, 1270,\n",
       "         104,  478, 1470,  564, 1214, 1138,  738, 1331,  458, 1002,  531,\n",
       "        1571,  678,  523,  617, 1314,  811,  261, 1471, 1440,  540, 1032,\n",
       "         172,  978,  235,  556, 1156, 1311,  282, 1201, 1137,  628,  758,\n",
       "        1244,  197,  711,  546,  280,  130,  828,  557, 1113,  954,  258,\n",
       "         578,  924,  148,  681, 1430, 1341, 1449, 1355,   40,  361,  324,\n",
       "         849, 1088, 1074,  599, 1543,  769, 1378,  279,  801,  142,   34,\n",
       "          14,  824,   84, 1291, 1018, 1120,  559, 1516,  386,  479, 1345,\n",
       "         955, 1383,  372, 1150, 1181,  173,  267,  311,  489,  803,  802,\n",
       "         187,  426, 1310,  145,  373,  666, 1394, 1114,  456,  203,  528,\n",
       "         147,   23,  207,  680,  879,  274, 1455,    2, 1401,  781, 1192,\n",
       "         344, 1332,  150,  698, 1252, 1550,  199,  886,   74,  834, 1318,\n",
       "         735, 1134,  832, 1062,   94,   27,  985,  388,   32, 1110,  966,\n",
       "        1042,  945,   79, 1197, 1143,  589,  519,  446,  689, 1335,  766,\n",
       "         624,  934, 1231,  963, 1409, 1443,  571,  565,  107,  631,  751,\n",
       "        1372]),\n",
       " array([1561, 1232,   21, 1446,  408, 1236,   39,  980, 1427, 1381,  814,\n",
       "         138,   61,  384,  988, 1597, 1324, 1185,  198, 1486,  398,  796,\n",
       "         842,  403,  343,  882,  676,  374,  636,    3,    6, 1033,  383,\n",
       "         308,  255,  654, 1299, 1276,  943,  412,  169,  697,  896, 1212,\n",
       "          98,  550,  577,  227,  302,   37, 1066, 1224,  323,  514, 1469,\n",
       "         652,  297,  270, 1362, 1459,  460, 1444, 1551,  515,   45, 1298,\n",
       "        1482,  575,  119, 1277,   57,  847, 1439,  159,  780,  569, 1512,\n",
       "          81,  535, 1348,  576,  561,  477, 1051,  545,  683, 1441, 1226,\n",
       "        1452,   95, 1069, 1035,  912,  579, 1031,  116,  259,  638,  225,\n",
       "         339,    8,  218,  366,  195, 1302, 1342,   92, 1017,  973,  915,\n",
       "         447, 1317, 1016,  390,  284, 1557,  196, 1565, 1327, 1092, 1305,\n",
       "        1418, 1426,  496,  106,   75, 1059,   11,  864,  360,  468,  183,\n",
       "          58, 1338,  101,  727,  376,  871, 1400, 1555,  358, 1081, 1225,\n",
       "        1351,  562,  583, 1183,  254, 1079,  165, 1518,  752, 1572, 1525,\n",
       "         177, 1034,  437, 1590,  656, 1370,  205, 1000, 1382,  710,  294,\n",
       "         112,  220,  135, 1585, 1132, 1096,   85,  592,  690, 1442, 1005,\n",
       "        1292, 1596,  277, 1084,  228, 1386, 1334,  897, 1234, 1320,  448,\n",
       "        1203,   80, 1216,  657,   65,  822,  909,  836, 1356,  691, 1593,\n",
       "         303,  219,  646,  481,  567,  549,    1, 1560, 1503,  641,  778,\n",
       "          59,  743,  939,  249, 1129,  121, 1433,  213,  919, 1186,   28,\n",
       "         821,  554, 1479, 1594, 1466, 1435,  874, 1288,  405, 1502,  770,\n",
       "         677,  634, 1529, 1379,  999,  908,  932,  153,  243, 1532,  337,\n",
       "         423,  491,  471, 1580, 1396, 1246, 1180,  759,  718,  469, 1178,\n",
       "        1474,  584, 1587, 1567,   93, 1538,  805,  494,   41, 1380, 1004,\n",
       "         693,  757,  960,  762, 1228,  547, 1564,   54, 1336, 1205, 1119,\n",
       "         827,  568,  338,  841,  722,  333,  244,   24,  580,  799,  719,\n",
       "          17,  354, 1044,  965,  285,  947, 1095, 1558, 1027, 1350,  312,\n",
       "         295,   13, 1460, 1227,  327, 1190, 1087,  884, 1117,  663,  964,\n",
       "         899,  590,  672,  449,  131, 1307,  688,  625,  511, 1330, 1145,\n",
       "         935]),\n",
       " array([ 931,  644,  526,  498, 1001,  976,  127,  920,  863, 1220,  250,\n",
       "         595,  929,  287,  162, 1024,  223,  443,   97,  352,  428, 1420,\n",
       "         234,  673,  506,  936,  655,  601, 1126,  330, 1547,  880,  336,\n",
       "         699,  224,  326, 1058, 1501,   88, 1083,  881,  705,  111,  621,\n",
       "         349, 1569,  454, 1546,  305,  900, 1375,  406,   20,   69,  529,\n",
       "         201, 1091,   19, 1428,  572,  331, 1521,  992,   60, 1286,  524,\n",
       "         113,  926,  916, 1306, 1127,  313, 1403,  262, 1284, 1006,  930,\n",
       "         298, 1498, 1153,  696, 1264, 1098, 1456, 1513, 1254,  904,  643,\n",
       "         709,  665,  411, 1176,  741, 1279, 1274,  670,  516, 1195, 1526,\n",
       "        1344,  776,  500,  365, 1535, 1041,  858,  742, 1388,  351,  810,\n",
       "         918,   63,  730,  820,  868,  542, 1184,  525, 1300, 1261,  650,\n",
       "         340, 1489,  961, 1037,  341,  520,  706, 1519,  317,  367, 1106,\n",
       "         400,  168,  594,  505,  983,  204,  941, 1432,  775,  319,  192,\n",
       "        1146,  355,  715, 1191, 1200, 1333,  679, 1271,  459, 1509, 1275,\n",
       "        1451, 1566,  637,  745,  193, 1283,  174, 1464, 1167,  541,  537,\n",
       "         465,  740,   18,  645,  434,  843,  445, 1598, 1154,  439,  724,\n",
       "        1048,  792, 1595,  786,  826,  154, 1101, 1343, 1574, 1280,  309,\n",
       "         486, 1536,  877,  692,  490, 1423,  558,   48,  407,  612, 1411,\n",
       "         190,  560,  304,  245,  872, 1061,   30,   36, 1259,  553,  763,\n",
       "        1583, 1397, 1294,  774, 1108,  129,  635,  555,  848, 1256, 1162,\n",
       "         455,  163,   31, 1544,  493, 1196, 1229,   42, 1251,  885, 1553,\n",
       "         632,  402,  281, 1193,  933,  808,  959, 1520, 1028, 1255,  170,\n",
       "         418, 1177, 1384, 1462, 1067,  996,  206,  238,  401, 1175,  596,\n",
       "         667,  512, 1266,  379,  923, 1495,  155, 1548,  890, 1038, 1118,\n",
       "        1215,  925, 1377, 1528, 1187,  530,  940,  765, 1437, 1003,  950,\n",
       "        1425, 1111, 1570, 1368, 1559,  982,  813, 1060,  684,  800, 1323,\n",
       "         409,  993,  237,  296,  200,  375, 1387,   99,  686,  647,  109,\n",
       "         179,  622, 1267,  630, 1505, 1142,  986,  158, 1053,  134,  485,\n",
       "         887,   52, 1406, 1424,  329,  968,  736,  754, 1023, 1352,  725,\n",
       "          22]),\n",
       " array([ 784,  473,  608, 1019, 1347,  364,  289, 1269, 1588,  467,  604,\n",
       "          66,  451,  387, 1040,  210, 1490,  143, 1591,  716, 1208, 1312,\n",
       "        1523, 1531,  532, 1467, 1144,  682,   89,  221, 1250, 1461, 1131,\n",
       "         472, 1182,  623, 1290,  291,  570, 1562, 1273, 1112,  263,  420,\n",
       "         830,  140, 1265,  462,  911,  105,  726,  889, 1364,  942, 1174,\n",
       "         914, 1326,  613, 1148,  271, 1165, 1581, 1045,  518, 1408, 1412,\n",
       "          49, 1359, 1085,   53, 1100, 1573, 1483,  818, 1168,  639, 1166,\n",
       "        1050,  251,  497,  956,   25,   77,  248, 1589, 1399,  413,  969,\n",
       "         272, 1015,  240,  905,  310,  984, 1077,  241,  394, 1415,  951,\n",
       "         507, 1086,  898, 1309,  744, 1179,  278,  257,  585,  764,  273,\n",
       "         378,  306, 1297,   62,  260,  967,  502, 1063, 1253, 1135,  819,\n",
       "          55, 1328,  252,  714, 1025,  214,  875,  276,  721,  239,  325,\n",
       "        1221, 1233,   68,  895,  152, 1211,  396, 1457,   64, 1354,  854,\n",
       "        1139, 1541,  363, 1337,  128,  760,  440, 1218,  332, 1159, 1043,\n",
       "        1248, 1026,  563,  702,  242, 1099,  829, 1556,  100,  359, 1247,\n",
       "         369,  268, 1361,  794, 1030, 1391, 1272, 1539, 1468,  804,  536,\n",
       "        1007,  435,  605,  318, 1582,  972,   56, 1407,  357,  510, 1533,\n",
       "        1194,  380, 1249, 1210,   10,  597,  182, 1054,  627, 1089, 1213,\n",
       "        1140,  946,  137,  865,  907, 1500,  508,  700,  717,  771, 1072,\n",
       "        1238,  125,  869,  878, 1070,  256, 1586,  839, 1578,   91,   83,\n",
       "          16, 1515, 1429, 1207, 1071,  157, 1245, 1374, 1549,  883,  990,\n",
       "         971,  658,  382, 1242, 1094, 1093,   90,  674,  429,  102, 1078,\n",
       "         114,  457, 1012,  614,  913, 1151, 1133,  484,   43,  422,  593,\n",
       "          38, 1136,  588,  809,  998,  453,  817, 1369,  415,  160,  922,\n",
       "        1169, 1102,  474, 1281,   96, 1313, 1209, 1339,  749, 1577,  788,\n",
       "        1492, 1122,  226,  450,  876,  850,  381, 1230, 1485,  815,  761,\n",
       "        1055,  648, 1301,  321,  651, 1395, 1511,  835, 1507,  948,  442,\n",
       "        1527,  582, 1453,  750,  350, 1010,  873,  713,  371,  397,  389,\n",
       "        1188,  188,  921,  320, 1514,  712,  640, 1199,  122,    9,   67])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([720, 425, 917, ..., 122,   9,  67]),\n",
       " array([1366,  551, 1068, ...,  122,    9,   67]),\n",
       " array([1366,  551, 1068, ...,  122,    9,   67]),\n",
       " array([1366,  551, 1068, ...,  122,    9,   67]),\n",
       " array([1366,  551, 1068, ..., 1352,  725,   22])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.4    0.7    0.    ...  0.56   9.4    5.   ]\n",
      " [ 7.8    0.88   0.    ...  0.68   9.8    5.   ]\n",
      " [ 7.8    0.76   0.04  ...  0.65   9.8    5.   ]\n",
      " ...\n",
      " [ 6.3    0.51   0.13  ...  0.75  11.     6.   ]\n",
      " [ 5.9    0.645  0.12  ...  0.71  10.2    5.   ]\n",
      " [ 6.     0.31   0.47  ...  0.66  11.     6.   ]]\n"
     ]
    }
   ],
   "source": [
    "dataset = data.values\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :11]\n",
    "y = dataset[:, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucivan\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sgd = linear_model.SGDRegressor()\n",
    "\n",
    "total_sgd = 0.0\n",
    "for i in range(k):\n",
    "    sgd.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = sgd.predict(X[idx_test[i]])\n",
    "    total_sgd = total_sgd + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "total_lr = 0.0\n",
    "for i in range(k):\n",
    "    lr.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = lr.predict(X[idx_test[i]])\n",
    "    total_lr = total_lr + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvr = LinearSVR()\n",
    "\n",
    "total_lsvr = 0.0\n",
    "for i in range(k):\n",
    "    lsvr.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = lsvr.predict(X[idx_test[i]])\n",
    "    total_lsvr = total_lsvr + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "\n",
    "total_svr = 0.0\n",
    "for i in range(k):\n",
    "    svr.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = svr.predict(X[idx_test[i]])\n",
    "    total_svr = total_svr + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "total_rfr = 0.0\n",
    "for i in range(k):\n",
    "    rfr.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = rfr.predict(X[idx_test[i]])\n",
    "    total_rfr = total_rfr + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "total_gbr = 0.0\n",
    "for i in range(k):\n",
    "    gbr.fit(X[idx_train[i]],y[idx_train[i]])\n",
    "    y_pred = gbr.predict(X[idx_test[i]])\n",
    "    total_gbr = total_gbr + metrics.mean_squared_error(y[idx_test[i]],y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Faça um gráfico comparativo entre resultados das avaliações (Evaluation) dos modelos acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 1.998111703634277e+25\n",
      "LR: 2.138559979885571\n",
      "LSVR: 7.2676585682110355\n",
      "SVR: 2.4196899711002637\n",
      "RFR: 2.3182350279756267\n",
      "GBR: 1.9209249201781073\n"
     ]
    }
   ],
   "source": [
    "class_names = ['SGD','LR','LSVR','SVR','RFR','GBR']\n",
    "class_ = [total_sgd,total_lr,total_lsvr,total_svr,total_rfr,total_gbr]\n",
    "for i in range(0,len(class_names)):\n",
    "    print(class_names[i] + ': ' + str(class_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x219f3ceab70>,\n",
       "  <matplotlib.axis.XTick at 0x219f3cc3978>,\n",
       "  <matplotlib.axis.XTick at 0x219f3cb86a0>,\n",
       "  <matplotlib.axis.XTick at 0x219f3d6cd68>,\n",
       "  <matplotlib.axis.XTick at 0x219f3d75400>,\n",
       "  <matplotlib.axis.XTick at 0x219f3d75a58>],\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x219f394beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.bar(range(len(class_names)),class_)\n",
    "plt.xticks(range(len(class_names)), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Escolha o melhor algoritmo obtido a partir de cross validation e treine um modelo usando o dataset completo, ou seja, gere um modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Qual a diferença entre Stochastic Gradient Descent e Gradient Descent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch gradient descent computes the gradient using the whole dataset. This is great for convex, or relatively smooth error manifolds. In this case, we move somewhat directly towards an optimum solution, either local or global. Additionally, batch gradient descent, given an annealed learning rate, will eventually find the minimum located in it's basin of attraction.\n",
    "\n",
    "Stochastic gradient descent (SGD) computes the gradient using a single sample. Most applications of SGD actually use a minibatch of several samples, for reasons that will be explained a bit later. SGD works well (Not well, I suppose, but better than batch gradient descent) for error manifolds that have lots of local maxima/minima. In this case, the somewhat noisier gradient calculated using the reduced number of samples tends to jerk the model out of local minima into a region that hopefully is more optimal. Single samples are really noisy, while minibatches tend to average a little of the noise out. Thus, the amount of jerk is reduced when using minibatches. A good balance is struck when the minibatch size is small enough to avoid some of the poor local minima, but large enough that it doesn't avoid the global minima or better-performing local minima. (Incidently, this assumes that the best minima have a larger and deeper basin of attraction, and are therefore easier to fall into.)\n",
    "\n",
    "One benefit of SGD is that it's computationally a whole lot faster. Large datasets often can't be held in RAM, which makes vectorization much less efficient. Rather, each sample or batch of samples must be loaded, worked with, the results stored, and so on. Minibatch SGD, on the other hand, is usually intentionally made small enough to be computationally tractable.\n",
    "\n",
    "Usually, this computational advantage is leveraged by performing many more iterations of SGD, making many more steps than conventional batch gradient descent. This usually results in a model that is very close to that which would be found via batch gradient descent, or better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
